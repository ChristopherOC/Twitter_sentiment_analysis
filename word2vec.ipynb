{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5739ca24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\ai python\\p7oc\\env\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\ai python\\p7oc\\env\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\ai python\\p7oc\\env\\lib\\site-packages (from gensim) (1.15.3)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in c:\\ai python\\p7oc\\env\\lib\\site-packages (from gensim) (7.5.0)\n",
      "Requirement already satisfied: wrapt in c:\\ai python\\p7oc\\env\\lib\\site-packages (from smart_open>=1.8.1->gensim) (1.14.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69e325aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports essentiels\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, fbeta_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1bf148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement et pr√©paration des donn√©es\n",
    "df = pd.read_csv('datas/training.1600000.processed.noemoticon.csv',\n",
    "                 sep=',', encoding='latin-1', header=None)\n",
    "df.columns = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
    "df.target = df.target.replace(4, 1)  # Binarisation\n",
    "\n",
    "# √âchantillonnage pour r√©duction\n",
    "df_pos = df[df.target == 1].sample(8000, random_state=42)\n",
    "df_neg = df[df.target == 0].sample(8000, random_state=42)\n",
    "df_reduced = pd.concat([df_pos, df_neg]).sample(frac=1, random_state=42)\n",
    "\n",
    "texts = df_reduced.text.astype(str).values\n",
    "labels = df_reduced.target.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad39f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization et vocabulaire\n",
    "def simple_tokenize(text):\n",
    "    return re.findall(r\"\\w+\", text.lower())\n",
    "\n",
    "def build_vocab(texts, vocab_size=10000):\n",
    "    counter = Counter()\n",
    "    for t in texts:\n",
    "        counter.update(simple_tokenize(t))\n",
    "    most_common = counter.most_common(vocab_size - 2)\n",
    "    \n",
    "    word2idx = {'<PAD>': 0, '<OOV>': 1}\n",
    "    for i, (word, _) in enumerate(most_common, start=2):\n",
    "        word2idx[word] = i\n",
    "    return word2idx\n",
    "\n",
    "def texts_to_sequences(texts, word2idx):\n",
    "    sequences = []\n",
    "    for t in texts:\n",
    "        tokens = simple_tokenize(t)\n",
    "        seq = [word2idx.get(tok, 1) for tok in tokens]\n",
    "        sequences.append(seq)\n",
    "    return sequences\n",
    "\n",
    "def pad_sequences(sequences, maxlen=50):\n",
    "    arr = np.zeros((len(sequences), maxlen), dtype=np.int64)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        s = seq[:maxlen]\n",
    "        arr[i, :len(s)] = s\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ab831ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©paration des donn√©es\n",
    "vocab_size = 10000\n",
    "maxlen = 50\n",
    "\n",
    "word2idx = build_vocab(texts, vocab_size)\n",
    "sequences = texts_to_sequences(texts, word2idx)\n",
    "X = pad_sequences(sequences, maxlen)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bc96932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entra√Ænement Word2Vec...\n",
      "Embedding matrix cr√©√©e: (10000, 100)\n"
     ]
    }
   ],
   "source": [
    "# Entra√Ænement Word2Vec sur nos donn√©es\n",
    "embedding_dim = 100\n",
    "\n",
    "# Pr√©paration des phrases tokenis√©es pour Word2Vec\n",
    "tokenized_texts = [simple_tokenize(text) for text in texts]\n",
    "\n",
    "# Entra√Ænement du mod√®le Word2Vec\n",
    "print(\"Entra√Ænement Word2Vec...\")\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=tokenized_texts,\n",
    "    vector_size=embedding_dim,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    workers=4,\n",
    "    sg=1,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Cr√©ation de la matrice d'embedding\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, idx in word2idx.items():\n",
    "    if idx < vocab_size and word in w2v_model.wv:\n",
    "        embedding_matrix[idx] = w2v_model.wv[word]\n",
    "\n",
    "print(f\"Embedding matrix cr√©√©e: {embedding_matrix.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1292303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mod√®le LSTM PyTorch avec Word2Vec\n",
    "class LSTMSentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim=64, maxlen=50):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "        self.embedding.weight.requires_grad = False  # Word2Vec non trainable\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,\n",
    "                           batch_first=True, dropout=0.2, num_layers=1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        lstm_out, (hn, cn) = self.lstm(x)\n",
    "        hn = self.dropout(hn[-1])\n",
    "        out = torch.sigmoid(self.fc(hn)).squeeze()\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "457f1714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/330540034538193051', creation_time=1763668642900, experiment_id='330540034538193051', last_update_time=1763668642900, lifecycle_stage='active', name='Twitter_Sentiment_Models', tags={}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pr√©paration des donn√©es PyTorch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "X_train_torch = torch.LongTensor(X_train).to(device)\n",
    "y_train_torch = torch.FloatTensor(y_train).to(device)\n",
    "X_test_torch = torch.LongTensor(X_test).to(device)\n",
    "y_test_torch = torch.FloatTensor(y_test).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_torch, y_train_torch)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Configuration MLflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"Twitter_Sentiment_Models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4532281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour plot et log confusion matrix\n",
    "def plot_and_log_confusion_matrix(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Pr√©dictions')\n",
    "    plt.ylabel('Valeurs r√©elles')\n",
    "    plt.title(f'Matrice de confusion - {model_name}')\n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    img = Image.open(buf)\n",
    "    mlflow.log_image(img, f\"confusion_matrix_{model_name}.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "417bc818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\AI Python\\P7OC\\env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - loss 0.6933\n",
      "Epoch 2/3 - loss 0.6934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/11 19:59:49 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - loss 0.6932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/11 19:59:49 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/12/11 19:59:56 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/12/11 19:59:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Word2Vec\n",
      "Accuracy: 0.5053, F1: 0.6714, ROC-AUC: 0.5012\n",
      "üèÉ View run LSTMWord2Vec at: http://127.0.0.1:8080/#/experiments/330540034538193051/runs/c64576d201fd4cb6a16895eb3c5551fe\n",
      "üß™ View experiment at: http://127.0.0.1:8080/#/experiments/330540034538193051\n"
     ]
    }
   ],
   "source": [
    "# Entra√Ænement et logging MLflow\n",
    "with mlflow.start_run(run_name=\"LSTMWord2Vec\"):\n",
    "    model = LSTMSentiment(vocab_size, embedding_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # Entra√Ænement\n",
    "    model.train()\n",
    "    for epoch in range(3):\n",
    "        total_loss = 0.0\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/3 - loss {total_loss/len(train_loader):.4f}')\n",
    "    \n",
    "    # √âvaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds_proba = model(X_test_torch).cpu().numpy()\n",
    "    preds = (preds_proba > 0.5).astype(int)\n",
    "    \n",
    "    # M√©triques\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    prec = precision_score(y_test, preds)\n",
    "    rec = recall_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    f2 = fbeta_score(y_test, preds, beta=2)\n",
    "    roc_auc = roc_auc_score(y_test, preds_proba)\n",
    "    \n",
    "    # Logging m√©triques\n",
    "    mlflow.log_metrics({\n",
    "        'accuracy': acc,\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1_score': f1,\n",
    "        'f2_score': f2,\n",
    "        'roc_auc': roc_auc\n",
    "    })\n",
    "    \n",
    "    # Logging mod√®le\n",
    "    mlflow.pytorch.log_model(model, \"lstm_word2vec_model\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    plot_and_log_confusion_matrix(y_test, preds, \"LSTMWord2VecPyTorch\")\n",
    "    \n",
    "    print(\"LSTM Word2Vec\")\n",
    "    print(f\"Accuracy: {acc:.4f}, F1: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "    mlflow.end_run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e2c19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
