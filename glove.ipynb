{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02fad10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports essentiels\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, fbeta_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a19319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement et pr√©paration des donn√©es\n",
    "df = pd.read_csv(\"datas/training.1600000.processed.noemoticon.csv\", sep=',', encoding='latin-1', header=None)\n",
    "df.columns = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
    "df['target'] = df['target'].replace(4, 1)  # Binarisation\n",
    "\n",
    "# √âchantillonnage pour r√©duction\n",
    "df_pos = df[df['target'] == 1].sample(8000, random_state=42)\n",
    "df_neg = df[df['target'] == 0].sample(8000, random_state=42)\n",
    "df_reduced = pd.concat([df_pos, df_neg]).sample(frac=1, random_state=42)\n",
    "\n",
    "texts = df_reduced['text'].astype(str).values\n",
    "labels = df_reduced['target'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "550467d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization et vocabulaire (comme dans ton notebook)\n",
    "def simple_tokenize(text):\n",
    "    return re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "\n",
    "def build_vocab(texts, vocab_size=10000):\n",
    "    counter = Counter()\n",
    "    for t in texts:\n",
    "        counter.update(simple_tokenize(t))\n",
    "    most_common = counter.most_common(vocab_size - 2)\n",
    "    word2idx = {\"PAD\": 0, \"OOV\": 1}\n",
    "    for i, (word, _) in enumerate(most_common, start=2):\n",
    "        word2idx[word] = i\n",
    "    return word2idx\n",
    "\n",
    "def texts_to_sequences(texts, word2idx):\n",
    "    sequences = []\n",
    "    for t in texts:\n",
    "        tokens = simple_tokenize(t)\n",
    "        seq = [word2idx.get(tok, 1) for tok in tokens]\n",
    "        sequences.append(seq)\n",
    "    return sequences\n",
    "\n",
    "def pad_sequences_np(sequences, maxlen=50):\n",
    "    arr = np.zeros((len(sequences), maxlen), dtype=np.int64)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        s = seq[:maxlen]\n",
    "        arr[i, :len(s)] = s\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce3e757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©paration des donn√©es\n",
    "vocab_size = 10000\n",
    "maxlen = 50\n",
    "\n",
    "word2idx = build_vocab(texts, vocab_size)\n",
    "sequences = texts_to_sequences(texts, word2idx)\n",
    "X = pad_sequences_np(sequences, maxlen)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd62d1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement GloVe embeddings\n",
    "embedding_dim = 100\n",
    "embedding_index = {}\n",
    "with open(\"glove.6B.100d.txt\", encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coefs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0085210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice d'embedding GloVe\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, idx in word2idx.items():\n",
    "    if word in embedding_index:\n",
    "        embedding_matrix[idx] = embedding_index[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dd379bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mod√®le LSTM PyTorch avec GloVe\n",
    "class LSTMSentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim=64, maxlen=50):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "        self.embedding.weight.requires_grad = False  # Peut √™tre ajust√© pour optimisation\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, \n",
    "                           dropout=0.2, num_layers=1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        lstm_out, (hn, cn) = self.lstm(x)\n",
    "        hn = self.dropout(hn[-1])\n",
    "        out = torch.sigmoid(self.fc(hn)).squeeze()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7893a07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/330540034538193051', creation_time=1763668642900, experiment_id='330540034538193051', last_update_time=1763668642900, lifecycle_stage='active', name='Twitter_Sentiment_Models', tags={}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pr√©paration des donn√©es PyTorch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "X_train_torch = torch.LongTensor(X_train).to(device)\n",
    "y_train_torch = torch.FloatTensor(y_train).to(device)\n",
    "X_test_torch = torch.LongTensor(X_test).to(device)\n",
    "y_test_torch = torch.FloatTensor(y_test).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_torch, y_train_torch)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Configuration MLflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"Twitter_Sentiment_Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4357fb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour plot et log confusion matrix\n",
    "def plot_and_log_confusion_matrix(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Pr√©dictions')\n",
    "    plt.ylabel('Valeurs r√©elles')\n",
    "    plt.title(f'Matrice de confusion - {model_name}')\n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    img = Image.open(buf)\n",
    "    mlflow.log_image(img, f\"confusion_matrix_{model_name}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a1b7ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\AI Python\\P7OC\\env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - loss: 0.6933\n",
      "Epoch 2/3 - loss: 0.6931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/11 20:00:18 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - loss: 0.6934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/11 20:00:19 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/12/11 20:00:25 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/12/11 20:00:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM GloVe PyTorch logged successfully!\n",
      "Accuracy: 0.5053, F1: 0.6714, ROC-AUC: 0.5093\n",
      "üèÉ View run LSTM_GloVe_PyTorch at: http://127.0.0.1:8080/#/experiments/330540034538193051/runs/31c0e5c616544ba2ab78ecfd73b83dcb\n",
      "üß™ View experiment at: http://127.0.0.1:8080/#/experiments/330540034538193051\n"
     ]
    }
   ],
   "source": [
    "# Entra√Ænement et logging MLflow\n",
    "with mlflow.start_run(run_name=\"LSTM_GloVe_PyTorch\"):\n",
    "    model = LSTMSentiment(vocab_size, embedding_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # Entra√Ænement\n",
    "    model.train()\n",
    "    for epoch in range(3):\n",
    "        total_loss = 0.0\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/3 - loss: {total_loss/len(train_loader):.4f}')\n",
    "    \n",
    "    # √âvaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds_proba = model(X_test_torch).cpu().numpy()\n",
    "        preds = (preds_proba >= 0.5).astype(int)\n",
    "    \n",
    "    # M√©triques\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    prec = precision_score(y_test, preds)\n",
    "    rec = recall_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    f2 = fbeta_score(y_test, preds, beta=2)\n",
    "    roc_auc = roc_auc_score(y_test, preds_proba)\n",
    "    \n",
    "    # Logging m√©triques\n",
    "    mlflow.log_metrics({\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1_score\": f1,\n",
    "        \"f2_score\": f2,\n",
    "        \"roc_auc\": roc_auc\n",
    "    })\n",
    "    \n",
    "    # Logging mod√®le\n",
    "    mlflow.pytorch.log_model(model, \"lstm_glove_model\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    plot_and_log_confusion_matrix(y_test, preds, \"LSTM_GloVe_PyTorch\")\n",
    "    \n",
    "    print(\"LSTM GloVe PyTorch logged successfully!\")\n",
    "    print(f\"Accuracy: {acc:.4f}, F1: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b4afe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
